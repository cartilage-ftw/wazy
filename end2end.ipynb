{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial # for use with vmap\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import jax.scipy.stats.norm as norm\n",
    "import optax\n",
    "from jax_unirep.layers import AAEmbedding, mLSTM, mLSTMAvgHidden\n",
    "from jax_unirep.utils import load_params, load_embedding, seq_to_oh\n",
    "from jax_unirep.utils import *\n",
    "from jax_unirep import get_reps\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "def forward(x):\n",
    "    mlp = hk.nets.MLP([256, 32, 2])\n",
    "    return mlp(x)\n",
    "\n",
    "forward  = hk.without_apply_rng(hk.transform(forward))\n",
    "\n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, key, forward):\n",
    "        self.key = key\n",
    "        self.forward = forward\n",
    "\n",
    "    def deep_ensemble_loss(self, params, ins, labels):\n",
    "        outs = self.forward.apply(params, ins)\n",
    "        means = outs[0]\n",
    "        stds = outs[1]\n",
    "        n_log_likelihoods = 0.5*jnp.log(jnp.abs(stds)) + 0.5*(labels-means)**2/jnp.abs(stds)\n",
    "\n",
    "        return n_log_likelihoods[0]\n",
    "\n",
    "    def adv_loss_func(self, params, seqs, labels, loss_func):\n",
    "        epsilon = 1e-3\n",
    "        grad_inputs = jax.grad(loss_func, 1)(params, seqs, labels)\n",
    "        seqs_ = seqs + epsilon * jnp.sign(grad_inputs)\n",
    "\n",
    "        return loss_func(params, seqs, labels) + loss_func(params, seqs_, labels)\n",
    "\n",
    "    def train_mlp(self, external_keys, seqs, labels):\n",
    "        learning_rate = 1e-2\n",
    "        n_training_steps = 2\n",
    "        opt_init, opt_update = optax.chain(\n",
    "            optax.scale_by_adam(b1=0.9, b2=0.999, eps=1e-4),\n",
    "            optax.scale(-learning_rate) # minus sign -- minimizing the loss\n",
    "        )\n",
    "        self.key, key_ = jax.random.split(self.key, num=2)\n",
    "        self.params = self.forward.init(self.key, jax.random.normal(key_, shape=(1900,)))\n",
    "        opt_state = opt_init(self.params)\n",
    "\n",
    "        loss_trace=[]\n",
    "        for step in range(n_training_steps):\n",
    "            loss, grad=jax.value_and_grad(self.adv_loss_func)(self.params, seqs, labels, self.deep_ensemble_loss)\n",
    "            loss_trace.append(loss)\n",
    "\n",
    "            updates, opt_state = opt_update(grad, opt_state, self.params)\n",
    "            self.params = optax.apply_updates(self.params, updates)\n",
    "        outs = self.forward.apply(self.params, seqs)\n",
    "\n",
    "        #joint_outs = model_stack(outs)\n",
    "        return loss_trace, outs\n",
    "\n",
    "    def batch(self, seqs, labels):\n",
    "        self.ensemble_seqs = jnp.tile(seqs, (5, 1 ,1))\n",
    "        self.ensemble_labels = jax.lax.broadcast(labels, (5,))[...,jnp.newaxis]\n",
    "        self.b_training_mlp = jax.vmap(self.train_mlp, (None, 0, 0), (0, 0))\n",
    "        self.bb_training_mlp = jax.vmap(self.b_training_mlp, (0, 0, 0), (0, 0))\n",
    "        self.external_keys = jax.random.split(self.key, num=5)\n",
    "        self.external_keys = jnp.reshape(self.external_keys, (5, -1))\n",
    "\n",
    "\n",
    "\n",
    "    def model_stack(self):\n",
    "        mu = jnp.mean(self.outs[..., 0], axis=0)\n",
    "        std = jnp.mean(self.outs[...,1] + self.outs[...,0]**2,axis=0) - mu**2\n",
    "        return mu, std\n",
    "\n",
    "    def call_train(self):\n",
    "        self.loss_trace, self.outs = self.bb_training_mlp(self.external_keys, self.ensemble_seqs, self.ensemble_labels) # batched\n",
    "        self.joint_outs = self.model_stack()\n",
    "        \n",
    "    def apply_(self, new_model, seq):\n",
    "        outs = self.forward.apply(self.params,seq)\n",
    "        print(outs.shape)\n",
    "        mu,std = outs\n",
    "        #mu = jnp.mean(outs[0], axis=0)\n",
    "        #std = jnp.mean(outs[1] + outs[0]**2,axis=0) - mu**2\n",
    "        return mu, std\n",
    "\n",
    "\n",
    "\n",
    "seqs = ['MSADDGIVYCQMRQGPWEFHIVTVESSAYDWVVVPGARIALDKYNAACEQHWSCILRRGIDQKPYAPDMLKCQCSDMCHPSDSFTWEIDAEAWYCNTDNLFTGIALYKNNDDYPDWYPIRCLKHKNVTAAQVPLVHFNDNKFTHHVHNDMPACDFKFFKTPTVRHACQFGSIYHSKQSRMDYSDLMQDEKAKHLKESHNVVPDDGIIIDPYMDILFGGRMNNREHCAKNE',\n",
    "        'EKMHIKESATRMGFQYEYKLPYCIWAFIIGRAWHFVSLHGDQWDCWKMTFVIYSACSNGHIDGCEVQHANLSSGVLPARWFDAFQQNMKGFHKMKCGGFCTYAFLWGLAMRIYVRNMGNLAIYQNGGTSEWLTEFWYRLAGAVWPFKQFSINGECEHFWWSFHPFTLFDNPPAKDRNVTAYLHFDAHFYSIAMVWLMSPVVKGDSPVNCCAVDVEQSGESWALLNNWCAP',\n",
    "        'HSFHKYKHGNWKSEGDQCLKVGQLRDECPQVNTPMYCSWGPHYFSIFHWIIPVAKAYHMLHNIEQQVYRCHWQERYKELHDATKTHQLEWSFGKSVWCAHCKPYIGWYRSPAGWHMPIKPPATKNLWVVRHKSKRKEGTISWENTLTCVWFHEICYGHGVCHQVHPWVVDSNEEYEMQWMETEVGECSYPAERQGAWYSFTQQQKWICIHVCNMSSGRVFCWYVLQLFRN',\n",
    "        'LDHAVLKILQAMGPWNNRVEHPRLGKRSTEWPAAIYEGEPRWRLKCDTTATYYKAFETRWYNCHMTLTCWWHGATIRSKLTTMCMMVTNGYRDFYRYNDWKGRKATKHHPMVCIYEILWIAFMGCLHMWAGARVSKIWVGFCIFFASCLQMSPLKDWHNKCAFGRNNPLGMKGWGMMIGNSFCHIVHEMDNKYYAGAPVDEPFMYNQQVFGFGAMHCLCMADFCNEWGIQ',\n",
    "        'PERHHYIGFHCYMQLDAIQQNPHWNAHVLFRAFDYVSNYWTWITMYDKYQGFLGIYVTSCKVHEHGACKHCHWPICYDCGQHADKMLWRKSFALHGQSHAYRPLWDRDLTGVLGISIDLNQGIKVAEAEGEILYCNVTDMTVMMHQSVGVFWCHDMAYPQWTDWYSSDNMMNSIPEISHMKNYRVTMVHEPLFIWECVSEWTENAEHEGHLITVGSTGGKWDTGMEREVM',\n",
    "        'DPSQTIHCGTTGMSWGTMFKRSYILIIRYGTPEATCPCIVNCQIVVYWGCMFKKDRDPRGTPIQSTENFFKHAMMEPSYAGGTAHMEKEIEYRSQDSWHAYFSYWVKVWCYVCIALSQIPNVAHHGMHLHASPEDKKCANNWRFRYVAFIRIAHGCSWCYRECYNFRYDRYIAWNPVHLESVPEWWAHPAFEIVKDTVDDNQYSGADERQGDPIGGQPCLLCATWEDSWT',\n",
    "        'LIDLFSLTRKFSRMPCRHNMNESYKEEWCETNNVKEYPHEQLLDKRYDIITLDGCKRMYCRSESQRITELHFIRYNMLCWPDRCIPLQYSQYESNMPPPMMRMWGCYHFGTLMFMSYAMPPTGEKREIVGGKEDHSGDLEDAFTDEDFNMDPAHQDYRHIAGTWHEPMFEIRMRYELTCNNMWSPIYANNAGMKQLTICNNDKICPTEGRRRQREIFNYKLHGRDQCQHI',\n",
    "        'SCDVGPHPLHGQCTGMAKQVMETANIPQCPIDDHVTRATMGLIDAGACDRDRVCVREIWNVYYDKSTMKIIMDPPSDTCKHKSFYGDMMSHQQMGWLSECIIANMQHNLPWQLWESWMIHSEICMIKQRKVMMFCGIQSKYTEDFARFHPFILANTQYIIFKRPTTWPRVYAFLHRCMVLGWSAYGMTAMIPNTKETIKLAHCEKWPLTGSYTPSFVIFDGWLARKCQWP',\n",
    "        'DWIEHVHTFWVLMFISNYPQIVCGLINQIEPWKSKFHSLAGFNQGCQCEKNYQGPIQAINGINQLVTITTPINNQENVDKKPHPGSVHTKSDAITLRFNQGVHNIFMWDMATQGRASIPFLNNMNGGGLTDYSWEQVVTCHCHMTNDLELDPQMLYMWWIVSANAWMVNGMRRQHMACHWAQWEGFRWPRYVQSVPMKVLLTTQKIHWMQYFREKFCFILMKWQGYWYTV',\n",
    "        'RHWRAPLLMYRDKEVQITWHFRFMYHCDALTCSEVHCHARNFMVFGYSTPQNYNPVILYWVTWANTCLTPKGAYCARQMRMYATVTMSKINQMTITYLVDRQRQHWGLAFRSDNTCNHKWYLKHRCKVWNWGWLIDCYDLDRNLPKQVSRNQSSKSLRDLFNYIHYHWAMLPINIYCYSGDIWTTISTDDQFHIPTFIPCGKTVHEDLQPYEMCGMWHQCEDADYTMQPV',\n",
    "]\n",
    "labels = jnp.array([25.217391304347824,\n",
    "                    15.652173913043478,\n",
    "                    23.478260869565219,\n",
    "                    22.173913043478262,\n",
    "                    23.913043478260871,\n",
    "                    24.782608695652176,\n",
    "                    26.956521739130434,\n",
    "                    17.391304347826086,\n",
    "                    19.130434782608695,\n",
    "                    26.521739130434781\n",
    "                   ])\n",
    "seqs = get_reps(seqs)[0]\n",
    "\n",
    "model = MLP(key, forward)\n",
    "model.batch(seqs, labels)\n",
    "model.call_train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[2])>with<BatchTrace(level=2/0)>\n",
      "  with val = Traced<ShapedArray(float32[10,2])>with<BatchTrace(level=1/0)>\n",
      "               with val = DeviceArray([[[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]]], dtype=float32)\n",
      "                    batch_dim = 0\n",
      "       batch_dim = 0\n"
     ]
    }
   ],
   "source": [
    "#model.apply_(seqs[0])\n",
    "def forward2(x):\n",
    "    mlp2 = hk.nets.MLP([256, 32, 2])\n",
    "    return mlp2(x)\n",
    "\n",
    "forward2  = hk.without_apply_rng(hk.transform(forward2))\n",
    "params = forward2.init(key, jax.random.normal(key, shape=(1900,)))\n",
    "out = forward2.apply(model.params, seqs[0])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(key, forward)\n",
    "def end2end(key, model, forward, seqs, labels):\n",
    "    model.batch(seqs, labels)\n",
    "    model.call_train()\n",
    "    return self.joint_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00536008 -0.09600413  0.04200451 ...  0.03934921  0.10036227\n",
      " -0.00582207]\n",
      "Traced<ShapedArray(float32[2])>with<BatchTrace(level=2/0)>\n",
      "  with val = Traced<ShapedArray(float32[10,2])>with<BatchTrace(level=1/0)>\n",
      "               with val = DeviceArray([[[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]],\n",
      "                          \n",
      "                                       [[-3.2417736 ,  2.048891  ],\n",
      "                                        [-0.713571  ,  2.1600096 ],\n",
      "                                        [ 0.12612917, -6.1499877 ],\n",
      "                                        [-0.9862055 ,  2.7809763 ],\n",
      "                                        [ 0.78969663, -5.394996  ],\n",
      "                                        [ 0.62117404, -4.25655   ],\n",
      "                                        [ 0.5410639 , -5.2603903 ],\n",
      "                                        [-1.2641287 ,  3.5802088 ],\n",
      "                                        [-1.1202598 ,  3.6278844 ],\n",
      "                                        [-2.8280272 ,  5.2859383 ]]], dtype=float32)\n",
      "                    batch_dim = 0\n",
      "       batch_dim = 0\n"
     ]
    }
   ],
   "source": [
    "#print(seqs.shape)\n",
    "#ensemble_unirep_seq = jnp.tile(seqs, (5,1,1))\n",
    "#print(ensemble_unirep_seq.shape)\n",
    "print(seqs[0])\n",
    "outs = forward.apply(model.params, seqs[0])\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 32)\n",
      "(DeviceArray([-3.2417731 , -1.1716001 ,  0.15587394, -1.3546982 ,\n",
      "              0.9841746 ,  0.8379841 ,  0.62949824, -1.5348262 ,\n",
      "             -1.3603796 , -3.2406297 ], dtype=float32), DeviceArray([ 2.048892 ,  3.5862346, -6.970621 ,  3.8595724, -6.62054  ,\n",
      "             -5.538826 , -6.020439 ,  4.405252 ,  4.4307556,  6.0628967],            dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(model.params['mlp/~/linear_1']['w'].shape)\n",
    "print(model.joint_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_ei(model, X):\n",
    "    mu, std = model.joint_outs\n",
    "    best = jnp.max(mu)\n",
    "    epsilon = 0.1\n",
    "    z = (mu-best-epsilon)/std\n",
    "    return (mu-best-epsilon)*norm.cdf(z) + std*norm.pdf(z)\n",
    "\n",
    "def optimizer(model, init_vec):\n",
    "    ei = bayesian_ei(model)\n",
    "    eta = 1e-2\n",
    "    n_steps = 100\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size=1e-2, b1=0.8, b2=0.9, eps=1e-5)\n",
    "    opt_state = opt_init(init_vec)\n",
    "    \n",
    "    @jax.jit\n",
    "    def step(i, opt_state):\n",
    "        vec1900 = get_params(opt_state)\n",
    "        outs = model.forward.apply(model.params, vec1900)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def train_seqprop_adam(key, target_rep, init_logits, init_r, init_b, iter_num=100):\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size=1e-2, b1=0.8, b2=0.9, eps=1e-5)\n",
    "    #opt_init, opt_update, get_params = optimizers.adagrad(step_size=1e-2)\n",
    "    opt_state = opt_init((init_logits, init_r, init_b)) # initial state\n",
    "    logits_trace = []\n",
    "    loss_trace = []\n",
    "\n",
    "    @jax.jit\n",
    "    def step(key, i, opt_state):\n",
    "        key, subkey = jax.random.split(key, num=2)\n",
    "        p = get_params(opt_state)\n",
    "        logits, r, b = p\n",
    "        \n",
    "        sampled_vec, norm_logits = forward_seqprop(key, logits, r, b)\n",
    "        loss = loss_func(target_rep, sampled_vec)\n",
    "        g = jax.grad(g_loss_func, (1,2,3))(key, logits, r, b, target_rep)\n",
    "        return opt_update(i, g, opt_state), loss\n",
    "\n",
    "    for step_idx in range(iter_num):\n",
    "        #print(step_idx)\n",
    "        opt_state, loss = step(key, step_idx, opt_state)\n",
    "        #print(loss)\n",
    "        loss_trace.append(loss)\n",
    "        mid_logits, mid_r, mid_b = get_params(opt_state)\n",
    "        logits_trace.append(mid_logits)\n",
    "    final_logits, final_r, final_b = get_params(opt_state)\n",
    "    sampled_vec, _ = forward_seqprop(key, final_logits, final_r, final_b)\n",
    "    return sampled_vec, final_logits, logits_trace, loss_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpdesign",
   "language": "python",
   "name": "alpdesign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
