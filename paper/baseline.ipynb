{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpdesign.utils import *\n",
    "from alpdesign.mlp import *\n",
    "from jax_unirep import get_reps\n",
    "import alpdesign\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax_unirep\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_list = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V','B','Z','X','*']\n",
    "blosum92 = np.loadtxt(\"./blosum62.txt\", dtype='i', delimiter=' ')\n",
    "avg92 = jnp.sum(blosum92)/24/24\n",
    "sum92 = 0.\n",
    "for row in blosum92:\n",
    "    for aa in row:\n",
    "        sum92 += (aa-avg92)**2\n",
    "std92 = jnp.sqrt(sum92 / 24/24)\n",
    "\n",
    "def blosum(seq1, seq2):\n",
    "    seqlist1 = list(seq1)\n",
    "    seqlist2 = list(seq2)\n",
    "    score = 0.\n",
    "    for i in range(len(seqlist1)):\n",
    "        idx1 = AA_list.index(seqlist1[i])\n",
    "        idx2 = AA_list.index(seqlist2[i])\n",
    "        score += (blosum92[idx1][idx2] - avg92)/std92\n",
    "        #jax.nn.sigmoid(score/len(seqlist1))\n",
    "    return score/len(seqlist1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25870454  1.2281255   1.7359174   1.5051029  -0.01827284  0.16637878\n",
      "  0.12021587  0.30486745 -0.01827285  0.25870457  0.9049851  -0.01827284]\n"
     ]
    }
   ],
   "source": [
    "target_seq = 'GIGAVLKVLT'\n",
    "oh_vec = encode_seq(list(target_seq))\n",
    "oh_unirep = seq2useq(oh_vec)\n",
    "target_rep = differentiable_jax_unirep(oh_unirep)\n",
    "'''\n",
    "seqs = ['GIGAVLKVLKAGLPALIVTLKRKIVQ',\n",
    "       'PPGATLKKHTTGSVALISWIWARIQQ',\n",
    "       'GIGAVLKVLTTGLKTLISAAKRKRAA',\n",
    "       'HAPPVLKVLTTGLAPPLVWIKRKRTH',\n",
    "       'GIGAVLUIHKLSSVAAWRPPKRKRQQ',\n",
    "       'PTWIIFLKAQWEQHSNLTNMRTFPEV',\n",
    "        'TISHFVCNHDICAWIKDMQAMQIKMC',\n",
    "        'CESWLWKRLFDGHADRWRSMPDYPIW',\n",
    "        'YLVENPLMFPLVAAFIHQWTRQISWH',\n",
    "        'QTEERLEAQISIYYIGAWSHYKVTDE']\n",
    "'''\n",
    "\n",
    "seqs = ['SSVAAWRPPK',\n",
    "       'PPGATLKKHT',\n",
    "       'LTGAVLKVLK',\n",
    "       'HAPPVLKVLT',\n",
    "       'AWRPPKRKRQ',\n",
    "       'PTWIIFLKAQ',\n",
    "       'TISHFVCNHD',\n",
    "       'CESWLWKRLF',\n",
    "       'YLVENPLMFP',\n",
    "       'QTEERLEAQI',\n",
    "       'GAWSHYKVTD',\n",
    "       'HADRWRSMPD']\n",
    "reps = get_reps(seqs)[0]\n",
    "labels = []\n",
    "for seq in seqs:\n",
    "    labels.append(blosum(target_seq, seq))\n",
    "labels = np.array(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "class NaiveBlock(hk.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out = hk.nets.MLP((256, 128, 64, 1,))(x)\n",
    "        return out\n",
    "    \n",
    "def naive_forward(x):\n",
    "    f = NaiveBlock()\n",
    "    return f(x)\n",
    "naive_forward_t = hk.without_apply_rng(hk.transform(naive_forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _naive_loss(forward, params, seq, label):\n",
    "    yhat = forward(params, seq) #scalar\n",
    "    return (label-yhat)**2\n",
    "\n",
    "def _shuffle_in_unison(key, a, b):\n",
    "    # NOTE to future self: do not try to rely on keys being same\n",
    "    # something about shape of arrays makes shuffle not the same\n",
    "    assert len(a) == len(b)\n",
    "    p = jax.random.permutation(key, len(a))\n",
    "    return jnp.array([a[i] for i in p]), jnp.array([b[i] for i in p])\n",
    "\n",
    "\n",
    "def _fill_to_batch(x, y, key, batch_size):\n",
    "    if len(y) >= batch_size:\n",
    "        return x, y\n",
    "    i = jax.random.choice(key, jnp.arange(len(y)),\n",
    "                          shape=(batch_size,), replace=True)\n",
    "    x = x[i, ...]\n",
    "    y = y[i, ...]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def naive_train(key, forward_t, seqs, labels, val_seqs=None, val_labels=None, params=None, epochs=3, batch_size=8, learning_rate=1e-2):\n",
    "    opt_init, opt_update = optax.chain(\n",
    "        optax.scale_by_adam(b1=0.8, b2=0.9, eps=1e-4),\n",
    "        optax.scale(-learning_rate)  # minus sign -- minimizing the loss\n",
    "    )\n",
    "\n",
    "    key, bkey = jax.random.split(key)\n",
    "\n",
    "    # fill in seqs/labels if too small\n",
    "    seqs, labels = _fill_to_batch(seqs, labels, bkey, batch_size)\n",
    "   \n",
    "        \n",
    "    if params == None:\n",
    "        params = forward_t.init(key, seqs[0])\n",
    "  \n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    # wrap loss in batch/sum\n",
    "    loss_ = partial(_naive_loss, forward_t.apply)\n",
    "    loss_fxn = lambda *args: jnp.mean(jax.vmap(loss_, in_axes=(None, 0, 0))(*args))\n",
    "    #loss_fxn = jnp.mean(jax.vmap(loss_, in_axes=(None, 0, 0)))\n",
    "\n",
    "    @jax.jit\n",
    "    def train_step(opt_state, params, seqs, labels):\n",
    "        loss, grad = jax.value_and_grad(loss_fxn, 0)(\n",
    "            params, seqs, labels)\n",
    "        updates, opt_state = opt_update(grad, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return opt_state, params, loss\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle seqs and labels\n",
    "        key, key_ = jax.random.split(key, num=2)\n",
    "        shuffle_seqs, shuffle_labels = _shuffle_in_unison(key, seqs, labels)\n",
    "        for i in range(0, len(shuffle_labels) // batch_size):\n",
    "            seq = shuffle_seqs[i:(i+1) * batch_size]\n",
    "            label = shuffle_labels[i:(i+1) * batch_size]\n",
    "            opt_state, params, loss = train_step(opt_state, params, seq, label)\n",
    "            losses.append(loss)\n",
    "        # compute validation loss\n",
    "        if val_seqs is not None:\n",
    "            val_loss = 0.\n",
    "            for i in range(0, len(val_labels) // batch_size):\n",
    "                seq = shuffle_seqs[i:(i+1) * batch_size]\n",
    "                label = shuffle_seqs[i:(i+1) * batch_size]\n",
    "                val_loss += loss_fxn(\n",
    "                    params,\n",
    "                    val_seqs[i:(i+1) * batch_size],\n",
    "                    val_labels[i:(i+1) * batch_size])\n",
    "            val_loss = val_loss/len(val_labels) * batch_size\n",
    "            #batch_loss += loss\n",
    "            val_losses.append(val_loss)\n",
    "    return (params, losses) if val_seqs is None else (params, losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff47058a190>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params, losses = naive_train(\n",
    "    key, naive_forward_t, reps, labels, epochs=160, learning_rate=1e-3)\n",
    "#forward_t = hk.without_apply_rng(hk.transform(forward_fxn))\n",
    "#forward = functools.partial(forward_t.apply, params)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2e(params, logits): # params is trained mlp params\n",
    "    s = alpdesign.SeqpropBlock()(logits)\n",
    "    us = alpdesign.seq2useq(s)\n",
    "    u = alpdesign.differentiable_jax_unirep(us)\n",
    "    forward = functools.partial(naive_forward_t.apply, params)\n",
    "    return forward(u)\n",
    "#e2e_t = hk.transform(e2e)\n",
    "#init_logits = jax.random.normal(key, shape=((10, 20)))\n",
    "#e2e_params = e2e_t.init(key, init_logits)\n",
    "\n",
    "def e2e_fxn(e2e_t, x, key):\n",
    "    e2e_params, logits = x\n",
    "    yhat = e2e_t.apply(e2e_params, key, logits)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_opt(key, f, init_x=None, iter_num=500, learning_rate=1e-2):\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(init_x)\n",
    "    x = init_x\n",
    "    reduced_f = lambda *args: jnp.mean(f(*args))\n",
    "    \n",
    "    @jax.jit\n",
    "    def step(x, opt_state, key):\n",
    "        loss, g = jax.value_and_grad(reduced_f, 0)(x, key)\n",
    "        updates, opt_state = optimizer.update(g, opt_state)\n",
    "        x = optax.apply_updates(x, updates)\n",
    "        return x, opt_state, loss\n",
    "    losses = []\n",
    "    for step_idx in range(iter_num):\n",
    "        key, _ = jax.random.split(key, num=2)\n",
    "        x, opt_state, loss= step(x, opt_state, key)\n",
    "        losses.append(loss)\n",
    "            \n",
    "    return x, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "BO_batch_size = 16\n",
    "reps = get_reps(seqs)[0]\n",
    "labels = []\n",
    "for seq in seqs:\n",
    "    labels.append(blosum(target_seq, seq))\n",
    "labels = np.array(labels)\n",
    "def loop(key, reps, labels, params, rb=None):\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    params, mlp_loss= naive_train(key, naive_forward_t, reps, labels, params=params, epochs=160)\n",
    "    # make random point\n",
    "    init_logits = 0.1*jax.random.normal(key, shape=((10, 20)))\n",
    "    e2e_ = lambda logits: functools.partial(e2e, params)(logits)\n",
    "    e2e_t = hk.transform(e2e_)\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    if rb is None:\n",
    "        rb = e2e_t.init(key, init_logits)\n",
    "    e2e_params = rb\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    #init_x = 0.1*jax.random.normal(key, shape=(BO_batch_size, 10, 20))\n",
    "    #forward = jax.vmap(lambda x, key: forward_t.apply(params, x), in_axes=(0, None))\n",
    "    print('start optimizing')\n",
    "    #batch_e2e = jax.vmap(lambda x, key: functools.partial(e2e_fxn, e2e_t)(params, x), in_axes=((None, 0), None))\n",
    "    batch_e2e = functools.partial(e2e_fxn, e2e_t)\n",
    "    #batched_x, bo_losses = alpdesign.mlp.bayes_opt(key, batch_e2e, labels, (e2e_t.init(train_key, init_logits), init_x), epsilon=0.01, iter_num=500)\n",
    "    x, losses = gradient_opt(key, batch_e2e, (e2e_params, init_logits))\n",
    "    #top_idx = np.argmin(bo_losses[-1])\n",
    "    rb = x[0]\n",
    "    logits = x[1]\n",
    "    \n",
    "    vec = alpdesign.seq.forward_seqprop.apply(rb, key, logits)\n",
    "    s = decode_seq(vec)\n",
    "    reps = np.concatenate((reps, get_reps([s])[0]))\n",
    "    #print(get_reps([s])[0])\n",
    "    y = blosum(target_seq, s)\n",
    "    predicted_y = naive_forward_t.apply(params, get_reps([s])[0])\n",
    "    #print(reps.shape)\n",
    "    print(s, y, predicted_y)\n",
    "    labels = np.concatenate((labels, np.array(y).reshape(1,)))\n",
    "    return key, reps, labels, s, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start optimizing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'forward_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9264097beea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblosum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-254cc44833f2>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(key, reps, labels, params, rb)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#print(get_reps([s])[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblosum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m#print(reps.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forward_t' is not defined"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    rb = None\n",
    "    params = None\n",
    "    key, reps, labels, final_vec, params= loop(key, reps, labels, params)\n",
    "    print(final_vec)\n",
    "    y.append(blosum(target_seq, final_vec))\n",
    "    yhat.append(forward_t.apply(params, get_reps([final_vec])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpdesign",
   "language": "python",
   "name": "alpdesign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
